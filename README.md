# ğŸ§  Mimir - Terminal AI Assistant

> **Your intelligent terminal companion powered by local LLMs**

Mimir is a lightweight, fast terminal troubleshooting assistant that runs entirely locally using Ollama. Get instant shell commands for any task without leaving your terminal.



## âœ¨ Features

- ğŸš€ **Lightning Fast** - Uses TinyLlama by default for instant responses
- ğŸ”’ **100% Local** - No API keys, no data sharing, complete privacy
- ğŸ¯ **Command Focused** - Returns pure shell commands, no explanations
- ğŸ“š **Smart History** - Searches your bash history and previous interactions
- ğŸ”§ **Configurable** - Multiple model profiles and customizable settings
- â­ **Model Management** - Easy switching between different LLM models
- ğŸ“– **Man Page Integration** - Quick access to manual pages

## ğŸš€ Quick Start

### One-Line Installation
```bash
curl -fsSL https://raw.githubusercontent.com/your-username/mimir/main/install.sh | bash
```

### Manual Installation
```bash
git clone https://github.com/your-username/mimir.git
cd mimir
chmod +x install.sh
./install.sh
```

## ğŸ’¡ Usage Examples

```bash
# Get shell commands instantly
mimir "show running processes"
# Output: ps aux

mimir "find large files"
# Output: find / -size +100M 2>/dev/null

mimir "check disk space"
# Output: df -h

# Search your command history
mimir "docker" --history

# Search previous Mimir interactions
mimir "processes" --logs

# Get man page summaries
mimir "grep" --man
```

## ğŸ›ï¸ Model Management

```bash
# List available models
mimir --models

# Switch models on the fly
mimir --model "llama3.2:3b"

# Interactive model selection
mimir --select-model

# Use model profiles
mimir --profile powerful

# Reset to TinyLlama default
mimir --reset-default
```

## âš™ï¸ Configuration

Mimir creates a `mimir_config.json` file for customization:

```json
{
  "model": "tinyllama:latest",
  "temperature": 0.1,
  "use_default_model": true,
  "profiles": {
    "lightweight": {"model": "tinyllama:latest", "temperature": 0.1},
    "balanced": {"model": "llama3.2:1b", "temperature": 0.2},
    "powerful": {"model": "llama3.2:3b", "temperature": 0.1}
  }
}
```

### Available Commands

| Command | Description |
|---------|-------------|
| `mimir "query"` | Get shell command for your query |
| `--models` | List all available Ollama models |
| `--model MODEL` | Set specific model to use |
| `--select-model` | Interactive model selection menu |
| `--profile PROFILE` | Switch to predefined profile |
| `--config` | Show current configuration |
| `--history` | Search bash history with query |
| `--logs` | Search previous Mimir interactions |
| `--man` | Show man page summary |
| `--favorites` | Show favorite models |
| `--reset-default` | Reset to TinyLlama default |
| `--temp FLOAT` | Set model temperature (0.0-1.0) |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Terminal    â”‚â”€â”€â”€â–¶â”‚      Mimir      â”‚â”€â”€â”€â–¶â”‚     Ollama      â”‚
â”‚   (Your Query)  â”‚    â”‚   (Processor)   â”‚    â”‚   (Local LLM)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  Command Output â”‚
                       â”‚   (Pure Shell)  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Requirements

- **Python 3.7+**
- **Ollama** (automatically installed by installer)
- **Linux/macOS** (Windows support via WSL)
- **2GB+ RAM** (for TinyLlama)

## ğŸ“‹ Installation Details

The installer script will:

1. âœ… Install Ollama if not present
2. âœ… Pull TinyLlama model (1.1GB)
3. âœ… Install Python dependencies
4. âœ… Make `mimir` globally available
5. âœ… Create default configuration

## ğŸ¯ Why Mimir?

- **Privacy First**: Everything runs locally, no data leaves your machine
- **Terminal Native**: Designed for command-line workflows
- **Lightweight**: Uses efficient models for fast responses
- **No Subscriptions**: Free and open source forever
- **Offline Ready**: Works without internet after initial setup

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.ai/) for making local LLMs accessible
- [TinyLlama](https://github.com/jzhang38/TinyLlama) for the efficient base model
- The open source AI community

## ğŸ“ Support

- ğŸ› **Bug Reports**: [GitHub Issues](https://github.com/your-username/mimir/issues)
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/your-username/mimir/discussions)
- ğŸ“– **Documentation**: [Wiki](https://github.com/your-username/mimir/wiki)

---

**Made with â¤ï¸ for terminal enthusiasts**

*"In Norse mythology, Mimir was known for his knowledge and wisdom. Our Mimir brings that same wisdom to your terminal."*
